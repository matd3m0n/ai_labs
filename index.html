<html>

<head>
<link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.13.2/css/jquery.dataTables.min.css">
<script type="text/javascript" language="javascript" src="https://code.jquery.com/jquery-3.5.1.js"></script>
<script type="text/javascript" language="javascript" src="https://cdn.datatables.net/1.13.2/js/jquery.dataTables.min.js"></script>
<script type="text/javascript" class="init">
$(document).ready(function () {
	$('#tab_industry').DataTable();
});
	</script>
<script type="text/javascript" class="init">
$(document).ready(function () {
	$('#tab_academia').DataTable();
});
	</script>

<style>
a:link {
  color: blue;
  background-color: transparent;
  text-decoration: none;
}
a:visited {
  color: blue;
  background-color: transparent;
  text-decoration: none;
}
a:hover {
  color: red;
  background-color: transparent;
  text-decoration: underline;
}
a:active {
  color: blue;
  background-color: transparent;
  text-decoration: underline;
}
</style>


</head>

<body>

<h1>Computer Vision and Machinie Learning labs</h1>

<h2> Industry </h2>



<table id="tab_industry" class="display" style="width:100%">
        <thead>
            <tr>
                <th>Name</th>
                <th>Location</th>
                <th>Head</th>
                <th>Areas</th>
                <th>Keywords</th>
				<th>Conferences</th>
                <th>PubCount</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><a href="https://prior.allenai.org/" target="_blank">Allen Institute for AI, PRIOR </a></td>
                <td>Seattle, Washington, US</td>
                <td><a href="https://anikem.github.io/" target="_blank">Aniruddha Kembhavi</a></td>
                <td>CV, </td>
                <td>  
                <div title='Physics-based vision and shape-from-X', style='display: inline-block' >PVS, </div>
                <div title='Robot vision', style='display: inline-block'>RV, </div>
                <div title='Vision + language', style='display: inline-block'>VL, </div>
                <div title='Explainable computer vision', style='display: inline-block'>ECV,</div>
                <div title='Datasets and evaluation', style='display: inline-block'>DE, </div>
                </td>
				<td>1x TMLR, 1xNeurIPS, 3xECCV, 5xCVPR, 1xAAAI</td>
                <td>11 </td>
            </tr>
            <tr>
                <td><a href="https://www.nec-labs.com/research/media-analytics/home/" target="_blank">NEC-labs, Media Analytics</a></td>
                <td>San Jose, California, US</td>
                <td><a href="https://www.nec-labs.com/research/media-analytics/people/manmohan-chandraker/" target="_blank">Manmohan Chandraker</a></td>
                <td>CV, </td>
                <td><div title="Scene analysis and understanding", style='display: inline-block'>SAU, </div>
                    <div title='Face and gesture', style='display: inline-block'>FG, </div>
                    <div title='Transfer/low-shot/long-tail learning ', style='display: inline-block'>TLLL, </div>
                    <div title='Deep learning architectures & techniques', style='display: inline-block'>DLAT, </div>
                     </td>
				<td>5xCVPR</td>
                <td>5 </td>
            </tr>
            <tr>
                <td><a href="https://sites.google.com/view/vittoferrari#h.p_aFjntAcaFBpO" target="_blank">Google Zurich, CV and ML lab</a></td>
                <td>Zurich, Switzerland, Europe</td>
                <td><a href="https://sites.google.com/view/vittoferrari/home" target="_blank">Vittorio Ferrari</a></td>
                <td>CV, </td>
                <td>     
                <div title="Recognition: detection, categorization, retrieval", style='display: inline-block'>RDCR, </div>
                    <div title="Datasets and evaluation", style='display: inline-block'>DE, </div>

                    <div title="Transfer/low-shot/long-tail learning", style='display: inline-block'>TLLL, </div>
                    <div title="3D from multi-view & sensors", style='display: inline-block'>3DM, </div>
                    <div title="Physics-based vision and shape-from-X", style='display: inline-block'>PVS </div>
                </td>
				<td>3xECCV, 5xCVPR, 2xTPAMI, 2xWACV</td>
                <td>12</td>
            </tr>
            <tr>
                <td><a href="https://research.samsung.com/aicenter_toronto" target="_blank">Samsung AI Center, Toronto</a></td>
                <td>Toronto, Canada</td>
                <td><a href="http://www.cs.toronto.edu/~sven/" target="_blank">Sven Dickinson</a>,
					<a href="http://www.cs.toronto.edu/~jepson/" target="_blank">Allan Jepson</a></td>
                <td>CV </td>
                <td>
                    <div title="Representation learning", style='display: inline-block'>RL, </div>
                    <div title="Video analysis and understanding", style='display: inline-block'>VAU, </div>


                </td>
				<td>2xCVPR, 1xECCV, 1xWACV</td>
                <td>5</td>
            </tr>
            <tr>
                <td><a href="https://research.samsung.com/aicentre_cambridge" target="_blank">Samsung AI Center, Cambridge</a></td>
                <td>Cambridge, England, Europe</td>
                <td><a href="http://niclane.org/" target="_blank">Nicholas Lane</a>,
                <a href="https://homepages.inf.ed.ac.uk/thospeda/" target="_blank">Timothy Hospedales</a>,
					<a href="https://ytzimiro.github.io/" target="_blank">Georgios Tzimiropoulos</a></td>
                <td>CV </td>
                <td>
                    <div title="Machine Learning", style='display: inline-block'>ML, </div>
                    <div title="Transfer/low-shot/long-tail learning", style='display: inline-block'>TLLL, </div>
                    <div title="Face and gesture", style='display: inline-block'>FG ,</div>

                </td>
				<td>1CVPR, 3xECCV, 1xICML, 1xICLR</td>
                <td>6</td>
            </tr>

            <tr>
                <td><a href="http://vladlen.info/" target="_blank">Apple Koltun Lab</a></td>
                <td>US</td>
                <td><a href="http://vladlen.info/" target="_blank">Vladlen Koltun</a>
                <td>CV,ML </td>
                <td>
                    <div title="Deep learning architectures & techniques", style='display: inline-block'>DLAT, </div>

                    <div title="Machine Learning", style='display: inline-block'>ML, </div>
                    <div title="Physics-based vision and shape-from-X", style='display: inline-block'>PVS, </div>
                    <div title="Computational photography", style='display: inline-block'>CP, </div>
                    <div title="Recognition: detection, categorization, retrieval", style='display: inline-block'>RDCR, </div>
                    <div title="Motion and tracking", style='display: inline-block'>MT, </div>
                    <div title="segmentation, grouping and shape analysis", style='display: inline-block'>SGSA, </div>
                    <div title="Robot vision", style='display: inline-block'>RV, </div>

                </td>
				<td>1xScience Robotics, 2xICLR, 4xCVPR, 4xNeurIPS</td>
                <td>11</td>
            </tr>

            <tr>
                <td><a href="https://research.nvidia.com/person/anima-anandkumar" target="_blank">Nvidia Anima Lab</a></td>
                <td>Santa Clara, California, US</td>
                <td><a href="https://research.nvidia.com/person/anima-anandkumar" target="_blank">Anima Anandkumar</a>
                <td>CV,ML </td>
                <td>
                    <div title="Robot Vision", style='display: inline-block'>RV, </div>
                    <div title="Image and video synthesis and generation", style='display: inline-block'>IVSG, </div>
                    <div title="Recognition: detection, categorization, retrieval", style='display: inline-block'>RDCR, </div>
                    <div title="Adversarial attacks & defense", style='display: inline-block'>AAD, </div>
                </td>
				<td>1xCVPR, 1xICML, 1xECCV, 1xCoRL</td>
                <td>4</td>
            </tr>
            <tr>
                <td><a href="https://www.microsoft.com/en-us/research/lab/mixed-reality-ai-zurich/" target="_blank">MSR Mixed Reality and AI Lab</a></td>
                <td>Zurich, Switzerland, Europe</td>
                <td><a href="https://people.inf.ethz.ch/pomarc/" target="_blank">Marc Pollefeys</a>
                <td>CV </td>
                <td>
                    <div title="3D from multi-view & sensors", style='display: inline-block'>3DM, </div>
                    <div title="pose estimation & tracking", style='display: inline-block'>PET, </div>
                    <div title="Datasets and Evaluation", style='display: inline-block'>DE, </div> 
                </td>
				<td>4xCVPR, 1xECCV</td>
                <td>5</td>
            </tr>



</table>

<br><br><br>


<h2> Academia </h2>
<table id="tab_academia" class="display" style="width:100%">
        <thead>
            <tr>
                <th>Name</th>
                <th>Location</th>
                <th>Head</th>
                <th>Areas</th>
                <th>Keywords</th>
				<td>Conferences</td>
                <th>PubCount</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td><a href="https://geometry.stanford.edu/index.html" target="_blank">Geometric Computic Group, Stanford University</a></td>
                <td>Stanford, California, US</td>
                <td><a href="https://geometry.stanford.edu/member/guibas/index.html" target="_blank">Leonidas Guibas</a></td>
                <td>CV, </td>
                <td>
                    <div title="Robot vision", style='display: inline-block'>RV, </div>

                    <div title="Representation learning", style='display: inline-block'>RL, </div>
                    <div title="Transfer/low-shot/long-tail learning ", style='display: inline-block'>TLLL, </div>
                    <div title="segmentation, grouping and shape analysis", style='display: inline-block'>SGSA, </div>
                    <div title="Navigation and autonomous driving", style='display: inline-block'>NAD, </div>
                </td>
				<td>1xRSS, 7xCVPR, 1xSIGGRAPH, 3xICLR, 1xRAL</td>
                <td>13</td>
            </tr>

            <tr>
                <td><a href="https://raivn.cs.washington.edu/" target="_blank">RAIVN Lab, University of Washington</a></td>
                <td>Seattle, Washington, US</td>
                <td><a href="https://homes.cs.washington.edu/~ali/" target="_blank">Ali Farhadi</td>
                <td>CV, </td>
                <td>
                    <div title="Vision + language", style='display: inline-block'>VL, </div>

                    <div title="Transfer/low-shot/long-tail learning", style='display: inline-block'>TLLL, </div>
                    <div title="Machine Learning", style='display: inline-block'>ML, </div>
                    <div title="Robot vision", style='display: inline-block'>RV, </div>
                    <div title="Scene analysis and understanding ", style='display: inline-block'>SAU, </div>
                    <div title="Datasets and evaluation", style='display: inline-block'>DE, </div>
                    <div title="Representation learning", style='display: inline-block'>RL, </div>

                </td>
				<td>5xNeurIPS, 2xECCV, 1xICML, 4XCVPR</td>
                <td>16</td>
            </tr>

            <tr>
                <td><a href="https://www.computationalimaging.org/" target="_blank">Stanford Computational Imaging, Stanford University</a></td>
                <td>Stanford, California, US</td>
                <td><a href="https://web.stanford.edu/~gordonwz/" target="_blank">Gordon Wetzstein</td>
                <td>CV, </td>
                <td>
                    <div title="Computational photography", style='display: inline-block'>CP, </div>
                    <div title="Representation learning", style='display: inline-block'>RL, </div>
                    <div title="Medical, biological and cell microscopy", style='display: inline-block'>MBCM, </div>
                    <div title="3D from multi-view & sensors", style='display: inline-block'>3DM, </div>
                </td>
				<td>2xCVPR, 2xICCP, 1xECCV, 2xSIGGRAPH, 1xICML, 1xNeurIPS</td>
                <td>9</td>
            </tr>
            <tr>
                <td><a href="http://tensorlab.cms.caltech.edu/users/anima/" target="_blank">Anima AI+Science Lab, Caltech</a></td>
                <td>Pasadena, California, US</td>
                <td><a href="http://tensorlab.cms.caltech.edu/users/anima/" target="_blank">Anima Anandkumar</td>
                <td>RV, CV, ML </td>
                <td>
                    <div title="Machine Learning", style='display: inline-block'>ML, </div>
                    <div title="Robotic Vision", style='display: inline-block'>RV, </div>
                    <div title="Image and video synthesis and generation", style='display: inline-block'>IVSG, </div>
                    <div title="Action & Event Recognition", style='display: inline-block'>AER, </div>
                    <div title="Visual Question Answering", style='display: inline-block'>VQA, </div>
                    <div title="Recognition: detection, categorization, retrieval", style='display: inline-block'>RDCR, </div>
                    <div title="Segmentation, Grouping and Shape Analysis", style='display: inline-block'>SGSA, </div>
                    <div title="Self-/semi-/meta-/unsupervised learning", style='display: inline-block'>SSMUL, </div>
                </td>
				<td>2xICLR, 4xCVPR, 1xICRA, 1xRSS, 3xNeurIPS, 2xICML, 1xRAL, 1xCOLT, </td>
                <td>15</td>
            </tr>

            <tr>
                <td><a href="https://gkioxari.github.io/" target="_blank">Georgia 3D vision lab, Caltech</a></td>
                <td>Pasadena, California, US</td>
                <td><a href="https://gkioxari.github.io/" target="_blank">Georgia Gkioxari</td>
                <td>CV</td>
                <td>
                    <div title="3D from multi-view & sensors", style='display: inline-block'>3DM, </div>
                    <div title="3D from single images", style='display: inline-block'>3DS, </div>

                </td>
				<td>2xCVPR</td>
                <td>2</td>
            </tr>


</table>

<p>
Notes: <br>

0. View source, request updates <a href="https://github.com/matd3m0n/ai_labs">here</a>.

<br>
1. <b>Areas</b> covers only last year of research (2022) <br>
a. CV - Computer Vision<br>

<br>

2. <b>Keywords</b> come from CVPR'2022 <a href="https://cvpr2022.thecvf.com/sites/default/files/2021-06/CFP_CVPR2022.pdf" target="_blank">Call for Papers</a>: <br>
3DR - 3D Reconstruction <br>
3DM = 3D from multi-view & sensors <br>
3DS = 3D from single images <br>

 AER = Action/event recognition <br>

 AER = action and event recognition <br>

 AAD = Adversarial attacks & defense <br>

 BA = Behavior analysis <br>

 BM = Biometrics <br>

 CP = Computational photography <br>

 CVT = Computer vision theory <br>

 CVSG = Computer vision for social good <br>

 DE = Datasets and evaluation <br>

 DLAT = Deep learning architectures & techniques <br>

 DAU = Document analysis and understanding <br>

 DAU = document analysis & understanding <br>

 ELI  = Efficient learning and inference <br>
 ECV = Explainable computer vision <br>

 FG = Face and gesture <br>
 IVSG = Image and video synthesis and generation <br>

 LLV = Low-level vision <br>

 ML = Machine Learning <br>

 MBCM = Medical, biological and cell microscopy <br>

 MT = Motion and tracking <br>
 NAD = Navigation and autonomous driving <br>

 OM = Optimization Methods <br>

 PRS = Photogrammetry and remote sensing <br>

 PVS = Physics-based vision and shape-from-X <br>

 PET = Pose estimation and tracking <br>

 PET = pose estimation & tracking <br>

 PET = human pose estimation & tracking, localization, and object pose estimation <br>
 
 PFL = Privacy & federated learning <br>

 PFL = privacy and federated learning <br>

 RDCR = Recognition: detection, categorization, retrieval <br>

 RL = Representation learning <br>

 SA = RGBD sensors and analytics <br>

 RV = Robot vision <br>

 SAU = Scene analysis and understanding <br>


 SGSA = segmentation, grouping and shape analysis <br>

 SM = Statistical Methods <br>

 TLLL = Transfer/low-shot/long-tail learning <br>

 TFAPEV = Transparency, fairness, accountability, privacy & ethics in vision: 

 TFAPEV = security, transparency, fairness, accountability, privacy & ethics in vision <br>

 SSMUL = Self-/semi-/meta-/unsupervised learning <br>



 VAU = Video analysis and understanding <br>
 VG = Vision + graphics <br>

 VG = vision & graphics <br>

 VL = Vision + language <br>
 VX = Vision + X <br>

VX  = vision & x <br>

VAS  = Vision applications and systems <br>

 VAS = vision applications & systems <br>

 VR = Visual reasoning <br>

<br>


              
<br> -->

3. <b>PubCount</b> covers research papers published in tier-1 conferences/journals in 2022

<br>


</p>




</body>

</html>
